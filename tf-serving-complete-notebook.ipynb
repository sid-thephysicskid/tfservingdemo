{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Deploy Models with TensorFlow Serving and Docker</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "ZQhSNW-CZUZh",
    "outputId": "0a0dd94e-b78f-4ffb-c819-5eae6efb6255"
   },
   "outputs": [],
   "source": [
    "#%%writefile -a train.py\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source. Download or import the csv from here, split it in test/train using your preferred method, and save the train and test csvs in the working directory: https://www.kaggle.com/snap/amazon-fine-food-reviews/data\n",
    "\n",
    "df = pd.read_csv('Reviews.csv')\n",
    "total_size=len(df)\n",
    "\n",
    "rng = RandomState()\n",
    "train = df.sample(frac=0.7, random_state=rng)\n",
    "test = df.loc[~df.index.isin(train.index)]\n",
    "\n",
    "train.to_csv('train.csv')\n",
    "test.to_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      Id   ProductId          UserId  ProfileName  \\\n",
      "0      243068  243069  B005K4Q4KG  A1Y5J68F22DRUR   Allison H.   \n",
      "1      456984  456985  B000N2XM4Q  A2ORH6OTUJO2EP  T. L. Graff   \n",
      "2      474540  474541  B002GWH7O2   A9QPAY95AMKPX    G. Scales   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       2      3  1322611200   \n",
      "1                     0                       0      4  1222214400   \n",
      "2                     0                       0      5  1325462400   \n",
      "\n",
      "                                   Summary  \\\n",
      "0                           It's decent...   \n",
      "1                              Primula tea   \n",
      "2  Very fragrant tea, well worth the price   \n",
      "\n",
      "                                                Text  \n",
      "0  This is okay cocoa. It's not really very smoot...  \n",
      "1  This is a wonderful product.  The only thing I...  \n",
      "2  I had accidentally ordered this tea for use du...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = 'train.csv'\n",
    "df_first3 = pd.read_csv(file_path, nrows=3)\n",
    "print(df_first3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile -a train.py\n",
    "\n",
    "## A base example reference notebook from TF: https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_text_classification.ipynb\n",
    "\n",
    "def load_dataset(file_path, num_samples):\n",
    "    df = pd.read_csv(file_path, usecols=[6, 9], nrows=num_samples)\n",
    "    df.columns = ['rating', 'title']\n",
    "\n",
    "    text = df['title'].tolist()\n",
    "    text = [str(t).encode('ascii', 'replace') for t in text]\n",
    "    text = np.array(text, dtype=object)[:]\n",
    "    \n",
    "    labels = df['rating'].tolist()\n",
    "    labels = [1 if i>=4 else 0 if i==3 else -1 for i in labels]\n",
    "    labels = np.array(pd.get_dummies(labels), dtype=int)[:] \n",
    "\n",
    "    return labels, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_labels, tmp_text = load_dataset('train1.csv', 100)\n",
    "tmp_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Build Model borrowed from TF Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile -a train.py\n",
    "##https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\n",
    "#paper: https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf\n",
    "\n",
    "def get_model():\n",
    "    hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim50/2\", output_shape=[50], \n",
    "                           input_shape=[], dtype=tf.string, name='tfhub_input', trainable=False)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(hub_layer)\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(3, activation='softmax', name='output'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=179, shape=(1, 50), dtype=float32, numpy=\n",
       "array([[ 0.11477911,  0.37569994,  0.3200057 ,  0.19149409,  0.04541118,\n",
       "        -0.08389199,  0.08161246,  0.08308495, -0.22092862, -0.02034098,\n",
       "        -0.09112693,  0.02896112,  0.13872515, -0.24331579,  0.16903718,\n",
       "        -0.32694525, -0.15207155,  0.05370582, -0.01047741, -0.17795743,\n",
       "        -0.08367762, -0.03455025,  0.1478257 ,  0.08285411, -0.11994869,\n",
       "         0.05815081, -0.49235696,  0.25065354,  0.1175537 , -0.10012385,\n",
       "        -0.20885593,  0.1405636 , -0.10900527, -0.22035465, -0.05779462,\n",
       "        -0.17156166,  0.05206814, -0.29343027, -0.0085016 , -0.0828478 ,\n",
       "        -0.0283776 , -0.11447106,  0.10054447,  0.20275821, -0.17710298,\n",
       "        -0.27764925,  0.15726376,  0.03514048, -0.0738261 ,  0.00131135]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/nnlm-en-dim50/2\")\n",
    "embeddings = embed([\"this is a test for the embeddings\"])\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile -a train.py\n",
    "\n",
    "def train(EPOCHS=4, BATCH_SIZE=32, TRAIN_FILE='train.csv', VAL_FILE='test.csv'):\n",
    "    WORKING_DIR = os.getcwd() #use to specify model checkpoint path\n",
    "    print(\"Loading training/validation data ...\")\n",
    "    y_train, x_train = load_dataset(TRAIN_FILE, num_samples=100000)\n",
    "    y_val, x_val = load_dataset(VAL_FILE, num_samples=10000)\n",
    "\n",
    "    print(\"Training the model ...\")\n",
    "    model = get_model()\n",
    "    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1,\n",
    "              validation_data=(x_val, y_val),\n",
    "              callbacks=[tf.keras.callbacks.ModelCheckpoint(os.path.join(WORKING_DIR,\n",
    "                                                                         'model_checkpoint'),\n",
    "                                                            monitor='val_loss', verbose=1,\n",
    "                                                            save_best_only=True,\n",
    "                                                            save_weights_only=False,\n",
    "                                                            mode='auto')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Train and Export Model as Protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training/validation data ...\n",
      "Training the model ...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "tfhub_input (KerasLayer)     (None, 50)                48190600  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                816       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 48,191,467\n",
      "Trainable params: 867\n",
      "Non-trainable params: 48,190,600\n",
      "_________________________________________________________________\n",
      "Train on 100000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 0.5984 - accuracy: 0.7822\n",
      "Epoch 00001: val_loss improved from inf to 0.57506, saving model to /Users/idelic/projects/tf-serving-test/review-model-v1/model_checkpoint\n",
      "INFO:tensorflow:Assets written to: /Users/idelic/projects/tf-serving-test/review-model-v1/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/idelic/projects/tf-serving-test/review-model-v1/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 16s 156us/sample - loss: 0.5984 - accuracy: 0.7822 - val_loss: 0.5751 - val_accuracy: 0.7872\n",
      "Epoch 2/4\n",
      " 99840/100000 [============================>.] - ETA: 0s - loss: 0.5671 - accuracy: 0.7906\n",
      "Epoch 00002: val_loss improved from 0.57506 to 0.56594, saving model to /Users/idelic/projects/tf-serving-test/review-model-v1/model_checkpoint\n",
      "INFO:tensorflow:Assets written to: /Users/idelic/projects/tf-serving-test/review-model-v1/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/idelic/projects/tf-serving-test/review-model-v1/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 15s 147us/sample - loss: 0.5669 - accuracy: 0.7907 - val_loss: 0.5659 - val_accuracy: 0.7884\n",
      "Epoch 3/4\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 0.5633 - accuracy: 0.7916\n",
      "Epoch 00003: val_loss improved from 0.56594 to 0.56443, saving model to /Users/idelic/projects/tf-serving-test/review-model-v1/model_checkpoint\n",
      "INFO:tensorflow:Assets written to: /Users/idelic/projects/tf-serving-test/review-model-v1/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/idelic/projects/tf-serving-test/review-model-v1/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 15s 148us/sample - loss: 0.5633 - accuracy: 0.7916 - val_loss: 0.5644 - val_accuracy: 0.7870\n",
      "Epoch 4/4\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 0.5602 - accuracy: 0.7920\n",
      "Epoch 00004: val_loss improved from 0.56443 to 0.56269, saving model to /Users/idelic/projects/tf-serving-test/review-model-v1/model_checkpoint\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd59d5c1cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd59d5c1cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/idelic/projects/tf-serving-test/review-model-v1/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/idelic/projects/tf-serving-test/review-model-v1/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 15s 150us/sample - loss: 0.5603 - accuracy: 0.7920 - val_loss: 0.5627 - val_accuracy: 0.7874\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd59d5c1cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd59d5c1cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/1624983773/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/1624983773/assets\n"
     ]
    }
   ],
   "source": [
    "#%%writefile -a train.py\n",
    "\n",
    "def export_model(model, base_path=\"models/\"):\n",
    "    path = os.path.join(base_path, str(int(time.time())))\n",
    "    tf.saved_model.save(model, path)\n",
    "\n",
    "\n",
    "if __name__== '__main__':\n",
    "    model = train()\n",
    "    export_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50390905, 0.20161174, 0.29447913]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = \"tastes bad, did not like it\"\n",
    "model.predict([test_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00405166, 0.00360874, 0.9923396 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = \"amazing book, great read\"\n",
    "model.predict([test_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: TensorFlow Serving with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`docker pull tensorflow/serving`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`docker run -p 8500:8500 \\\n",
    "            -p 8501:8501 \\\n",
    "            --mount type=bind,\\\n",
    "            source=models/,\\\n",
    "            target=/models/nnlm \\\n",
    "            -e MODEL_NAME=nnlm \\\n",
    "            -t tensorflow/serving`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7: Setup a REST Client to perform Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Model Prediction\n",
    "\n",
    "##### Support for gRPC and REST\n",
    "\n",
    "- TensorFlow Serving supports\n",
    "    - Remote Procedure Protocal (gRPC)\n",
    "    - Representational State Transfer (REST)\n",
    "- Consistent API structures\n",
    "- Server supports both standards simultaneously\n",
    "- Default ports:\n",
    "    - RPC: 8500\n",
    "    - REST: 8501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions via REST\n",
    "\n",
    "- Standard HTTP POST requests\n",
    "- Response is a JSON body with the prediction\n",
    "- Request from the default or specific model\n",
    "\n",
    "Default URI scheme:\n",
    "\n",
    "`http://{HOST}:{PORT}/v1/models/{MODEL_NAME}`\n",
    "\n",
    "Specific model versions:\n",
    "\n",
    "`http://{HOST}:{PORT}/v1/models/{MODEL_NAME}[/versions/{MODEL_VERSION}]:predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NND75SMZUsP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tf_serving_rest_client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tf_serving_rest_client.py\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "def get_rest_url(model_name, host='127.0.0.1', port='8501', verb='predict', version=None):\n",
    "    \"\"\" generate the URL path\"\"\"\n",
    "    url = \"http://{host}:{port}/v1/models/{model_name}\".format(host=host, port=port, model_name=model_name)\n",
    "    if version:\n",
    "        url += 'versions/{version}'.format(version=version)\n",
    "    url += ':{verb}'.format(verb=verb)\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_model_prediction(model_input, model_name='nnlm', signature_name='serving_default'):\n",
    "    \"\"\" no error handling at all, just poc\"\"\"\n",
    "\n",
    "    url = get_rest_url(model_name)\n",
    "    #In the row format, inputs are keyed to instances key in the JSON request.\n",
    "    #When there is only one named input, specify the value of instances key to be the value of the input:\n",
    "    data = {\"instances\": [model_input]}\n",
    "    \n",
    "    rv = requests.post(url, data=json.dumps(data))\n",
    "    if rv.status_code != requests.codes.ok:\n",
    "        rv.raise_for_status()\n",
    "    \n",
    "    return rv.json()['predictions']\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print(\"\\nGenerate REST url ...\")\n",
    "    url = get_rest_url(model_name='nnlm')\n",
    "    print(url)\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nEnter a review [:q for Quit]\")\n",
    "        if sys.version_info[0] <= 3:\n",
    "            sentence = input()\n",
    "        if sentence == ':q':\n",
    "            break\n",
    "        model_input = sentence\n",
    "        model_prediction = get_model_prediction(model_input)\n",
    "        print(\"The model predicted ...\")\n",
    "        print(model_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8: Setup a gRPC Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference example: [https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_client.py](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_client.py#L152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions via gRPC\n",
    "\n",
    "More sophisticated client-server connections\n",
    "\n",
    "- Prediction data has to be converted to the Protobuf format\n",
    "- Request types have designated types, e.g. float, int, bytes\n",
    "- Payloads need to be converted to base64\n",
    "- Connect to the server via gRPC stubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gRPC vs REST: When to use which API standard\n",
    "\n",
    "- Rest is easy to implement and debug\n",
    "- RPC is more network efficient, smaller payloads\n",
    "- RPC can provide much faster inferences!\n",
    "- Mino-batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKJVOjDlZUvc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TidfRe2VZU39"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xA3wNmDSZU66"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deploy-TF-Serving.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
